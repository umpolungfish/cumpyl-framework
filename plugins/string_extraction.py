import re
import string
from typing import Dict, Any, List, Tuple, Set
import sys
import os

# ğ‘¨ğ‘› ğ‘ ğ‘ğ‘¸ğ‘§ğ‘¯ğ‘‘ ğ‘›ğ‘²ğ‘®ğ‘§ğ‘’ğ‘‘ğ‘¼ğ‘¦ ğ‘‘ ğ‘ ğ‘ğ‘­ğ‘” ğ‘“ğ‘¹ ğ‘¦ğ‘¥ğ‘ğ‘¹ğ‘‘ğ‘¦ğ‘™
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    from cumpyl_package.plugin_manager import AnalysisPlugin
except ImportError:
    import sys
    import os
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'cumpyl_package'))
    from plugin_manager import AnalysisPlugin


class StringExtractionPlugin(AnalysisPlugin):
    """ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ ğ‘¯ ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘²ğ‘Ÿ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘¦ğ‘¯ ğ‘šğ‘²ğ‘¯ğ‘©ğ‘®ğ‘¦ ğ‘“ğ‘²ğ‘¤ğ‘Ÿ"""
    
    def __init__(self, config):
        super().__init__(config)
        self.name = "string_extraction"
        self.version = "1.0.0"
        self.description = "Extracts and analyzes strings from binary sections with context analysis"
        self.author = "Cumpyl Framework"
        self.dependencies = []
        
        # ğ‘œğ‘§ğ‘‘ ğ‘’ğ‘ªğ‘¯ğ‘“ğ‘¦ğ‘œ ğ‘ğ‘¨ğ‘¤ğ‘¿ğ‘Ÿ
        plugin_config = self.get_config()
        self.min_string_length = plugin_config.get('min_string_length', 4)
        self.max_string_length = plugin_config.get('max_string_length', 200)
        self.include_unicode = plugin_config.get('include_unicode', True)
        self.extract_patterns = plugin_config.get('extract_patterns', True)
        
        # ğ‘¦ğ‘¯ğ‘¦ğ‘–ğ‘©ğ‘¤ğ‘²ğ‘Ÿ ğ‘®ğ‘§ğ‘’ğ‘Ÿ ğ‘ğ‘¨ğ‘‘ğ‘¼ğ‘¯ğ‘Ÿ
        self._init_patterns()
    
    def _init_patterns(self):
        """ğ‘¦ğ‘¯ğ‘¦ğ‘–ğ‘©ğ‘¤ğ‘²ğ‘Ÿ ğ‘®ğ‘§ğ‘œğ‘¿ğ‘¤ğ‘¼ ğ‘¦ğ‘’ğ‘•ğ‘ğ‘®ğ‘§ğ‘–ğ‘©ğ‘¯ ğ‘ğ‘¨ğ‘‘ğ‘¼ğ‘¯ğ‘Ÿ ğ‘“ğ‘¹ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ"""
        self.patterns = {
            # ğ‘¯ğ‘§ğ‘‘ğ‘¢ğ‘»ğ‘’ ğ‘®ğ‘¦ğ‘¤ğ‘±ğ‘‘ğ‘¦ğ‘›
            'ip_addresses': re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'),
            'urls': re.compile(r'https?://[^\s<>"\']+|www\.[^\s<>"\']+'),
            'domains': re.compile(r'\b[a-zA-Z0-9-]+\.(?:com|org|net|edu|gov|mil|int|co|io|me|tv|info|biz|name|pro|aero|coop|museum|[a-z]{2})\b'),
            'email_addresses': re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
            
            # ğ‘“ğ‘²ğ‘¤ ğ‘ğ‘­ğ‘”ğ‘•
            'file_paths_windows': re.compile(r'[A-Za-z]:\\[^<>:"|?*\x00-\x1f]+'),
            'file_paths_unix': re.compile(r'\/[^<>:"|?*\x00-\x1f\s]+'),
            'registry_keys': re.compile(r'HKEY_[A-Z_]+\\[^<>:"|?*\x00-\x1f]+'),
            
            # ğ‘“ğ‘¦ğ‘¤ ğ‘§ğ‘’ğ‘•ğ‘‘ğ‘§ğ‘¯ğ‘–ğ‘©ğ‘¯ğ‘Ÿ
            'executables': re.compile(r'\b\w+\.(?:exe|dll|sys|bat|cmd|ps1|vbs|js|jar|msi)\b', re.IGNORECASE),
            'documents': re.compile(r'\b\w+\.(?:doc|docx|pdf|txt|rtf|xls|xlsx|ppt|pptx)\b', re.IGNORECASE),
            'archives': re.compile(r'\b\w+\.(?:zip|rar|7z|tar|gz|bz2)\b', re.IGNORECASE),
            
            # ğ‘¦ğ‘¯ğ‘’ğ‘®ğ‘¦ğ‘ğ‘–ğ‘©ğ‘¯/ğ‘’ğ‘®ğ‘¦ğ‘ğ‘‘ğ‘´
            'base64_strings': re.compile(r'[A-Za-z0-9+/]{20,}={0,2}'),
            'hex_strings': re.compile(r'\b[0-9A-Fa-f]{16,}\b'),
            'crypto_indicators': re.compile(r'\b(?:AES|RSA|SHA|MD5|DES|RC4|PGP|SSL|TLS)\b', re.IGNORECASE),
            
            # ğ‘“ğ‘³ğ‘™ğ‘’ğ‘–ğ‘©ğ‘¯ ğ‘¯ğ‘±ğ‘¥ğ‘Ÿ
            'api_functions': re.compile(r'\b(?:CreateProcess|WriteProcessMemory|VirtualAlloc|LoadLibrary|GetProcAddress|RegSetValue|ShellExecute|WinExec|CreateFile|CreateThread|SetWindowsHook|keybd_event|mouse_event)\w*\b', re.IGNORECASE),
            'socket_functions': re.compile(r'\b(?:WSAStartup|socket|connect|send|recv|bind|listen|accept|gethostbyname|inet_addr)\w*\b', re.IGNORECASE),
            
            # ğ‘šğ‘±ğ‘• ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯
            'error_messages': re.compile(r'(?:error|fail|exception|invalid|access denied|not found|permission|denied)', re.IGNORECASE),
            'debug_strings': re.compile(r'(?:debug|trace|log|printf|fprintf|sprintf|assert)', re.IGNORECASE),
            
            # ğ‘•ğ‘¦ğ‘’ğ‘¢ğ‘®ğ‘¦ğ‘‘ğ‘¦ ğ‘®ğ‘¦ğ‘¤ğ‘±ğ‘‘ğ‘¦ğ‘›
            'passwords': re.compile(r'(?:password|passwd|pwd|pass|secret|key)[\s=:]*[\'"]?[A-Za-z0-9!@#$%^&*()_+-=]{4,}[\'"]?', re.IGNORECASE),
            'credit_cards': re.compile(r'\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|3[0-9]{13}|6(?:011|5[0-9]{2})[0-9]{12})\b'),
        }
        
        # ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘“ğ‘³ğ‘™ğ‘’ğ‘–ğ‘©ğ‘¯ ğ‘¯ğ‘±ğ‘¥ğ‘Ÿ (ğ‘©ğ‘’ğ‘•ğ‘ğ‘¨ğ‘¯ğ‘›ğ‘¦ğ‘› ğ‘¤ğ‘¦ğ‘•ğ‘‘)
        self.interesting_apis = {
            'process_manipulation': ['CreateProcess', 'OpenProcess', 'TerminateProcess', 'WriteProcessMemory', 'ReadProcessMemory', 'VirtualAllocEx'],
            'file_operations': ['CreateFile', 'WriteFile', 'ReadFile', 'DeleteFile', 'CopyFile', 'MoveFile'],
            'registry_operations': ['RegOpenKey', 'RegSetValue', 'RegGetValue', 'RegDeleteKey', 'RegCreateKey'],
            'network_operations': ['WSAStartup', 'socket', 'connect', 'send', 'recv', 'InternetOpen', 'HttpOpenRequest'],
            'crypto_operations': ['CryptAcquireContext', 'CryptCreateHash', 'CryptEncrypt', 'CryptDecrypt'],
            'hook_operations': ['SetWindowsHook', 'SetWinEventHook', 'CallNextHookEx'],
            'service_operations': ['CreateService', 'OpenService', 'StartService', 'ControlService'],
            'memory_operations': ['VirtualAlloc', 'VirtualProtect', 'HeapAlloc', 'GlobalAlloc']
        }
    
    def extract_ascii_strings(self, data: bytes) -> List[Dict[str, Any]]:
        """ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ ASCII ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘“ğ‘®ğ‘ªğ‘¥ ğ‘šğ‘²ğ‘¯ğ‘©ğ‘®ğ‘¦ ğ‘›ğ‘±ğ‘‘ğ‘©"""
        strings = []
        current_string = ""
        start_offset = 0
        
        for i, byte in enumerate(data):
            if 32 <= byte <= 126:  # ğ‘ğ‘®ğ‘¦ğ‘¯ğ‘‘ğ‘©ğ‘šğ‘©ğ‘¤ ASCII ğ‘®ğ‘±ğ‘¯ğ‘¡
                if not current_string:
                    start_offset = i
                current_string += chr(byte)
            else:
                if len(current_string) >= self.min_string_length:
                    strings.append({
                        'value': current_string[:self.max_string_length],
                        'offset': start_offset,
                        'length': len(current_string),
                        'type': 'ascii'
                    })
                current_string = ""
        
        # ğ‘—ğ‘§ğ‘’ ğ‘“ğ‘¹ ğ‘ ğ‘¤ğ‘­ğ‘•ğ‘‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™
        if len(current_string) >= self.min_string_length:
            strings.append({
                'value': current_string[:self.max_string_length],
                'offset': start_offset,
                'length': len(current_string),
                'type': 'ascii'
            })
        
        return strings
    
    def extract_unicode_strings(self, data: bytes) -> List[Dict[str, Any]]:
        """ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ Unicode (UTF-16) ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘“ğ‘®ğ‘ªğ‘¥ ğ‘šğ‘²ğ‘¯ğ‘©ğ‘®ğ‘¦ ğ‘›ğ‘±ğ‘‘ğ‘©"""
        strings = []
        current_string = ""
        start_offset = 0
        
        # ğ‘¤ğ‘«ğ‘’ ğ‘“ğ‘¹ UTF-16 ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ (ğ‘¤ğ‘¦ğ‘‘ğ‘©ğ‘¤ ğ‘§ğ‘¯ğ‘›ğ‘¦ğ‘©ğ‘¯)
        for i in range(0, len(data) - 1, 2):
            if i + 1 < len(data):
                char_code = data[i] | (data[i + 1] << 8)
                
                # ğ‘—ğ‘§ğ‘’ ğ‘¦ğ‘“ ğ‘¦ğ‘‘'ğ‘• ğ‘© ğ‘ğ‘®ğ‘¦ğ‘¯ğ‘‘ğ‘©ğ‘šğ‘©ğ‘¤ Unicode ğ‘’ğ‘¸ğ‘¦ğ‘’ğ‘‘ğ‘¼
                if 32 <= char_code <= 126 or 160 <= char_code <= 255:
                    if not current_string:
                        start_offset = i
                    try:
                        current_string += chr(char_code)
                    except ValueError:
                        # ğ‘¦ğ‘¯ğ‘ğ‘¨ğ‘¤ğ‘¦ğ‘› Unicode ğ‘’ğ‘¸ğ‘¦ğ‘’ğ‘‘ğ‘¼
                        if len(current_string) >= self.min_string_length:
                            strings.append({
                                'value': current_string[:self.max_string_length],
                                'offset': start_offset,
                                'length': len(current_string) * 2,
                                'type': 'unicode'
                            })
                        current_string = ""
                else:
                    if len(current_string) >= self.min_string_length:
                        strings.append({
                            'value': current_string[:self.max_string_length],
                            'offset': start_offset,
                            'length': len(current_string) * 2,
                            'type': 'unicode'
                        })
                    current_string = ""
        
        # ğ‘—ğ‘§ğ‘’ ğ‘“ğ‘¹ ğ‘ ğ‘¤ğ‘­ğ‘•ğ‘‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™
        if len(current_string) >= self.min_string_length:
            strings.append({
                'value': current_string[:self.max_string_length],
                'offset': start_offset,
                'length': len(current_string) * 2,
                'type': 'unicode'
            })
        
        return strings
    
    def categorize_strings(self, strings: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """ğ‘’ğ‘¨ğ‘‘ğ‘©ğ‘œğ‘¼ğ‘²ğ‘Ÿ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘šğ‘±ğ‘•ğ‘‘ ğ‘ªğ‘¯ ğ‘ğ‘º ğ‘’ğ‘©ğ‘¯ğ‘‘ğ‘§ğ‘¯ğ‘‘"""
        categorized = {
            'network_indicators': [],
            'file_paths': [],
            'api_functions': [],
            'crypto_indicators': [],
            'error_messages': [],
            'debug_strings': [],
            'security_related': [],
            'interesting_patterns': [],
            'other': []
        }
        
        if not self.extract_patterns:
            categorized['other'] = strings
            return categorized
        
        for string_obj in strings:
            string_value = string_obj['value']
            matched_category = None
            
            # ğ‘—ğ‘§ğ‘’ ğ‘©ğ‘œğ‘±ğ‘¯ğ‘•ğ‘‘ ğ‘ ğ‘ğ‘¨ğ‘‘ğ‘¼ğ‘¯ğ‘Ÿ
            for pattern_name, pattern in self.patterns.items():
                if pattern.search(string_value):
                    string_obj['pattern_match'] = pattern_name
                    
                    # ğ‘¥ğ‘¨ğ‘ ğ‘ğ‘¨ğ‘‘ğ‘¼ğ‘¯ ğ‘¯ğ‘±ğ‘¥ğ‘Ÿ ğ‘‘ ğ‘’ğ‘¨ğ‘‘ğ‘©ğ‘œğ‘¼ğ‘¦ğ‘Ÿ
                    if pattern_name in ['ip_addresses', 'urls', 'domains', 'email_addresses']:
                        matched_category = 'network_indicators'
                    elif pattern_name in ['file_paths_windows', 'file_paths_unix', 'registry_keys']:
                        matched_category = 'file_paths'
                    elif pattern_name in ['api_functions', 'socket_functions']:
                        matched_category = 'api_functions'
                    elif pattern_name in ['base64_strings', 'hex_strings', 'crypto_indicators']:
                        matched_category = 'crypto_indicators'
                    elif pattern_name in ['error_messages']:
                        matched_category = 'error_messages'
                    elif pattern_name in ['debug_strings']:
                        matched_category = 'debug_strings'
                    elif pattern_name in ['passwords', 'credit_cards']:
                        matched_category = 'security_related'
                    else:
                        matched_category = 'interesting_patterns'
                    break
            
            # ğ‘—ğ‘§ğ‘’ ğ‘©ğ‘œğ‘±ğ‘¯ğ‘•ğ‘‘ API ğ‘“ğ‘³ğ‘™ğ‘’ğ‘–ğ‘©ğ‘¯ ğ‘¤ğ‘¦ğ‘•ğ‘‘ğ‘•
            if matched_category is None:
                for category, apis in self.interesting_apis.items():
                    for api in apis:
                        if api.lower() in string_value.lower():
                            string_obj['api_category'] = category
                            matched_category = 'api_functions'
                            break
                    if matched_category:
                        break
            
            # ğ‘¨ğ‘› ğ‘‘ ğ‘ ğ‘©ğ‘ğ‘®ğ‘´ğ‘ğ‘®ğ‘¦ğ‘¦ğ‘‘ ğ‘’ğ‘¨ğ‘‘ğ‘©ğ‘œğ‘¼ğ‘¦
            if matched_category:
                categorized[matched_category].append(string_obj)
            else:
                categorized['other'].append(string_obj)
        
        return categorized
    
    def analyze_string_context(self, strings: List[Dict[str, Any]], section_data: bytes) -> List[Dict[str, Any]]:
        """ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘²ğ‘Ÿ ğ‘ ğ‘’ğ‘©ğ‘¯ğ‘‘ğ‘§ğ‘’ğ‘•ğ‘‘ ğ‘©ğ‘®ğ‘¬ğ‘¯ğ‘› ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ"""
        enriched_strings = []
        
        for string_obj in strings:
            offset = string_obj['offset']
            context_size = 32
            
            # ğ‘œğ‘§ğ‘‘ ğ‘šğ‘²ğ‘‘ğ‘• ğ‘šğ‘¦ğ‘“ğ‘¹ ğ‘¯ ğ‘­ğ‘“ğ‘‘ğ‘¼ ğ‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™
            start = max(0, offset - context_size)
            end = min(len(section_data), offset + string_obj['length'] + context_size)
            
            context_bytes = section_data[start:end]
            string_obj['context'] = {
                'hex': context_bytes.hex(),
                'offset_start': start,
                'offset_end': end
            }
            
            # ğ‘’ğ‘¨ğ‘¤ğ‘’ğ‘¿ğ‘¤ğ‘±ğ‘‘ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ ğ‘•ğ‘’ğ‘¹
            interest_score = self._calculate_interest_score(string_obj)
            string_obj['interest_score'] = interest_score
            
            enriched_strings.append(string_obj)
        
        # ğ‘•ğ‘¹ğ‘‘ ğ‘šğ‘² ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ ğ‘•ğ‘’ğ‘¹ (ğ‘£ğ‘¦ğ‘œğ‘¼ ğ‘¦ğ‘Ÿ ğ‘¥ğ‘¹ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™)
        enriched_strings.sort(key=lambda x: x['interest_score'], reverse=True)
        
        return enriched_strings
    
    def _calculate_interest_score(self, string_obj: Dict[str, Any]) -> float:
        """ğ‘’ğ‘¨ğ‘¤ğ‘’ğ‘¿ğ‘¤ğ‘±ğ‘‘ ğ‘© ğ‘¯ğ‘¿ğ‘¥ğ‘§ğ‘®ğ‘¦ğ‘’ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ ğ‘•ğ‘’ğ‘¹ ğ‘“ğ‘¹ ğ‘© ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™"""
        score = 0.0
        string_value = string_obj['value'].lower()
        
        # ğ‘¤ğ‘§ğ‘™ğ‘” ğ‘šğ‘´ğ‘¯ğ‘©ğ‘•
        if string_obj['length'] > 10:
            score += 1.0
        
        # ğ‘ğ‘¨ğ‘‘ğ‘¼ğ‘¯ ğ‘¥ğ‘¨ğ‘— ğ‘šğ‘´ğ‘¯ğ‘©ğ‘•
        if 'pattern_match' in string_obj:
            pattern_name = string_obj['pattern_match']
            if pattern_name in ['ip_addresses', 'urls', 'domains']:
                score += 5.0
            elif pattern_name in ['api_functions', 'socket_functions']:
                score += 4.0
            elif pattern_name in ['passwords', 'credit_cards']:
                score += 6.0
            elif pattern_name in ['crypto_indicators', 'base64_strings']:
                score += 3.0
            else:
                score += 2.0
        
        # API ğ‘’ğ‘¨ğ‘‘ğ‘©ğ‘œğ‘¼ğ‘¦ ğ‘šğ‘´ğ‘¯ğ‘©ğ‘•
        if 'api_category' in string_obj:
            category = string_obj['api_category']
            if category in ['process_manipulation', 'hook_operations']:
                score += 4.0
            elif category in ['network_operations', 'crypto_operations']:
                score += 3.5
            else:
                score += 2.0
        
        # ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘’ğ‘°ğ‘¢ğ‘»ğ‘› ğ‘šğ‘´ğ‘¯ğ‘©ğ‘•
        interesting_keywords = [
            'malware', 'virus', 'trojan', 'backdoor', 'keylog', 'rootkit',
            'exploit', 'payload', 'shellcode', 'inject', 'hook', 'stealth',
            'bypass', 'evasion', 'persistence', 'privilege', 'escalation'
        ]
        
        for keyword in interesting_keywords:
            if keyword in string_value:
                score += 3.0
        
        # ğ‘¦ğ‘¯ğ‘’ğ‘®ğ‘¦ğ‘ğ‘–ğ‘©ğ‘¯/ğ‘§ğ‘¯ğ‘’ğ‘´ğ‘›ğ‘¦ğ‘™ ğ‘¦ğ‘¯ğ‘›ğ‘¦ğ‘’ğ‘±ğ‘‘ğ‘¼ğ‘Ÿ
        if len(string_value) > 20 and all(c in 'abcdefghijklmnopqrstuvwxyz0123456789+/=' for c in string_value):
            score += 2.0  # ğ‘ğ‘ªğ‘•ğ‘¦ğ‘šğ‘©ğ‘¤ base64
        
        return score
    
    def analyze(self, rewriter) -> Dict[str, Any]:
        """ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘²ğ‘Ÿ ğ‘·ğ‘¤ ğ‘•ğ‘§ğ‘’ğ‘–ğ‘©ğ‘¯ğ‘Ÿ ğ‘¯ ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ"""
        results = {
            'sections': {},
            'summary': {
                'total_strings': 0,
                'interesting_strings': [],
                'api_functions_found': set(),
                'network_indicators': [],
                'security_related': []
            }
        }
        
        try:
            # ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘²ğ‘Ÿ ğ‘°ğ‘— ğ‘•ğ‘§ğ‘’ğ‘–ğ‘©ğ‘¯
            for section in rewriter.binary.sections:
                section_name = section.name
                section_data = bytes(section.content)
                
                if len(section_data) == 0:
                    continue
                
                # ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ ASCII ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ
                ascii_strings = self.extract_ascii_strings(section_data)
                
                # ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘®ğ‘¨ğ‘’ğ‘‘ Unicode ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘¦ğ‘“ ğ‘¦ğ‘¯ğ‘±ğ‘šğ‘©ğ‘¤ğ‘›
                unicode_strings = []
                if self.include_unicode:
                    unicode_strings = self.extract_unicode_strings(section_data)
                
                # ğ‘’ğ‘©ğ‘¥ğ‘šğ‘²ğ‘¯ ğ‘·ğ‘¤ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ
                all_strings = ascii_strings + unicode_strings
                
                # ğ‘’ğ‘¨ğ‘‘ğ‘©ğ‘œğ‘¼ğ‘²ğ‘Ÿ ğ‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ
                categorized = self.categorize_strings(all_strings)
                
                # ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘²ğ‘Ÿ ğ‘’ğ‘©ğ‘¯ğ‘‘ğ‘§ğ‘’ğ‘•ğ‘‘ ğ‘“ğ‘¹ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ
                high_interest_strings = []
                for category_strings in categorized.values():
                    high_interest_strings.extend(category_strings)
                
                enriched_strings = self.analyze_string_context(high_interest_strings, section_data)
                
                # ğ‘¦ğ‘ğ‘§ğ‘¯ğ‘‘ğ‘¦ğ‘“ğ‘² ğ‘‘ğ‘©ğ‘ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ (ğ‘‘ğ‘©ğ‘ 10)
                top_interesting = enriched_strings[:10]
                
                section_result = {
                    'string_count': {
                        'ascii': len(ascii_strings),
                        'unicode': len(unicode_strings),
                        'total': len(all_strings)
                    },
                    'categorized_strings': categorized,
                    'top_interesting': top_interesting,
                    'statistics': {
                        'avg_length': sum(s['length'] for s in all_strings) / len(all_strings) if all_strings else 0,
                        'max_length': max(s['length'] for s in all_strings) if all_strings else 0,
                        'min_length': min(s['length'] for s in all_strings) if all_strings else 0
                    }
                }
                
                results['sections'][section_name] = section_result
                results['summary']['total_strings'] += len(all_strings)
                
                # ğ‘¨ğ‘› ğ‘‘ ğ‘œğ‘¤ğ‘´ğ‘šğ‘©ğ‘¤ ğ‘•ğ‘§ğ‘‘ğ‘•
                for api_string in categorized['api_functions']:
                    results['summary']['api_functions_found'].add(api_string['value'])
                
                for net_string in categorized['network_indicators']:
                    results['summary']['network_indicators'].append({
                        'section': section_name,
                        'value': net_string['value'],
                        'type': net_string.get('pattern_match', 'unknown')
                    })
                
                for sec_string in categorized['security_related']:
                    results['summary']['security_related'].append({
                        'section': section_name,
                        'value': sec_string['value'],
                        'type': sec_string.get('pattern_match', 'unknown')
                    })
                
                # ğ‘¨ğ‘› ğ‘£ğ‘² ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘‘ ğ‘œğ‘¤ğ‘´ğ‘šğ‘©ğ‘¤ ğ‘¤ğ‘¦ğ‘•ğ‘‘
                for interesting_string in top_interesting:
                    if interesting_string['interest_score'] > 3.0:
                        results['summary']['interesting_strings'].append({
                            'section': section_name,
                            'value': interesting_string['value'],
                            'score': interesting_string['interest_score'],
                            'offset': interesting_string['offset']
                        })
        
        except Exception as e:
            results['error'] = str(e)
        
        # ğ‘’ğ‘©ğ‘¯ğ‘ğ‘»ğ‘‘ ğ‘•ğ‘§ğ‘‘ ğ‘‘ ğ‘¤ğ‘¦ğ‘•ğ‘‘ ğ‘“ğ‘¹ JSON ğ‘•ğ‘¦ğ‘®ğ‘¦ğ‘©ğ‘¤ğ‘²ğ‘Ÿğ‘±ğ‘–ğ‘©ğ‘¯
        results['summary']['api_functions_found'] = list(results['summary']['api_functions_found'])
        
        return results