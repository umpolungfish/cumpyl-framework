import json
import xml.etree.ElementTree as ET
import yaml
from datetime import datetime
from typing import Dict, Any, List, Optional
import os
from pathlib import Path
from abc import ABC, abstractmethod
try:
    from .config import ConfigManager
except ImportError:
    from config import ConfigManager


class ReportFormatter(ABC):
    """ğ‘šğ‘±ğ‘• ğ‘’ğ‘¤ğ‘­ğ‘• ğ‘“ğ‘¹ ğ‘·ğ‘¤ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘¼ğ‘Ÿ"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
    
    @abstractmethod
    def format(self, data: Dict[str, Any]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘ ğ‘›ğ‘±ğ‘‘ğ‘© ğ‘‘ ğ‘© ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™"""
        pass
    
    @abstractmethod
    def get_file_extension(self) -> str:
        """ğ‘œğ‘§ğ‘‘ ğ‘ ğ‘ğ‘¦ğ‘¤ ğ‘¦ğ‘’ğ‘•ğ‘‘ğ‘§ğ‘¯ğ‘–ğ‘©ğ‘¯ ğ‘“ğ‘¹ ğ‘ğ‘¦ğ‘• ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘"""
        pass


class JSONReportFormatter(ReportFormatter):
    """JSON ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘¼"""
    
    def format(self, data: Dict[str, Any]) -> str:
        return json.dumps(data, indent=2, default=str, ensure_ascii=False)
    
    def get_file_extension(self) -> str:
        return ".json"


class YAMLReportFormatter(ReportFormatter):
    """YAML ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘¼"""
    
    def format(self, data: Dict[str, Any]) -> str:
        return yaml.dump(data, default_flow_style=False, allow_unicode=True)
    
    def get_file_extension(self) -> str:
        return ".yaml"


class XMLReportFormatter(ReportFormatter):
    """XML ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘¼"""
    
    def format(self, data: Dict[str, Any]) -> str:
        root = ET.Element("cumpyl_report")
        self._dict_to_xml(data, root)
        ET.indent(root, space="  ")
        return ET.tostring(root, encoding='unicode')
    
    def _dict_to_xml(self, data: Any, parent: ET.Element):
        """ğ‘’ğ‘©ğ‘¯ğ‘ğ‘»ğ‘‘ ğ‘© ğ‘›ğ‘¦ğ‘’ğ‘–ğ‘©ğ‘¯ğ‘¼ğ‘¦ ğ‘‘ XML ğ‘¦ğ‘¤ğ‘©ğ‘¥ğ‘©ğ‘¯ğ‘‘ğ‘Ÿ"""
        if isinstance(data, dict):
            for key, value in data.items():
                # ğ‘ğ‘°ğ‘¯ XML ğ‘¦ğ‘¤ğ‘©ğ‘¥ğ‘©ğ‘¯ğ‘‘ ğ‘¯ğ‘±ğ‘¥ğ‘Ÿ
                clean_key = str(key).replace(' ', '_').replace('-', '_')
                if clean_key and (clean_key[0].isalpha() or clean_key[0] == '_'):
                    child = ET.SubElement(parent, clean_key)
                else:
                    child = ET.SubElement(parent, "item")
                    child.set("key", str(key))
                
                self._dict_to_xml(value, child)
        
        elif isinstance(data, list):
            for i, item in enumerate(data):
                child = ET.SubElement(parent, "item")
                child.set("index", str(i))
                self._dict_to_xml(item, child)
        
        else:
            parent.text = str(data) if data is not None else ""
    
    def get_file_extension(self) -> str:
        return ".xml"


class HTMLReportFormatter(ReportFormatter):
    """HTML ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘¼"""
    
    def format(self, data: Dict[str, Any]) -> str:
        html = self._generate_html_report(data)
        return html
    
    def _generate_html_report(self, data: Dict[str, Any]) -> str:
        """ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘© ğ‘’ğ‘©ğ‘¥ğ‘ğ‘¤ğ‘°ğ‘‘ HTML ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘"""
        metadata = data.get('metadata', {})
        title = f"Cumpyl Analysis Report - {metadata.get('target_file', 'Unknown')}"
        
        html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        {self._get_css_styles()}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ” Cumpyl Binary Analysis Report</h1>
            <div class="metadata">
                <p><strong>Target File:</strong> {metadata.get('target_file', 'N/A')}</p>
                <p><strong>Analysis Date:</strong> {metadata.get('timestamp', 'N/A')}</p>
                <p><strong>Framework Version:</strong> {metadata.get('framework_version', 'N/A')}</p>
            </div>
        </header>
        
        <main>
            {self._format_sections(data)}
        </main>
        
        <footer>
            <p>Generated by <strong>Cumpyl Framework</strong> - Binary Analysis & Rewriting Tool</p>
        </footer>
    </div>
</body>
</html>"""
        return html
    
    def _get_css_styles(self) -> str:
        """ğ‘®ğ‘¦ğ‘‘ğ‘»ğ‘¯ CSS ğ‘•ğ‘‘ğ‘²ğ‘¤ğ‘Ÿ ğ‘“ğ‘¹ ğ‘ HTML ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘"""
        return """
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
            color: #333;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        
        header {
            border-bottom: 3px solid #007acc;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        
        h1 {
            color: #007acc;
            margin: 0;
            font-size: 2.5em;
        }
        
        h2 {
            color: #005c99;
            border-bottom: 2px solid #007acc;
            padding-bottom: 5px;
            margin-top: 30px;
        }
        
        h3 {
            color: #007acc;
            margin-top: 25px;
        }
        
        .metadata {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin-top: 15px;
        }
        
        .metadata p {
            margin: 5px 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        
        th {
            background-color: #007acc;
            color: white;
            font-weight: bold;
        }
        
        tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        .code-block {
            background-color: #f8f8f8;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 15px;
            margin: 10px 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            overflow-x: auto;
        }
        
        .warning {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }
        
        .success {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }
        
        .error {
            background-color: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }
        
        .stat-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .stat-card {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #007acc;
        }
        
        .stat-card h4 {
            margin: 0 0 10px 0;
            color: #007acc;
        }
        
        .stat-value {
            font-size: 1.5em;
            font-weight: bold;
            color: #333;
        }
        
        footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
        }
        """
    
    def _format_sections(self, data: Dict[str, Any]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘·ğ‘¤ ğ‘ ğ‘¤ğ‘® ğ‘•ğ‘§ğ‘’ğ‘–ğ‘©ğ‘¯ğ‘Ÿ ğ‘¦ğ‘¯ğ‘‘ HTML"""
        sections = []
        
        # ğ‘ ğ‘ ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘¦ğ‘Ÿğ‘¦ğ‘• ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ
        if 'analysis_results' in data:
            sections.append(self._format_analysis_results(data['analysis_results']))
        
        # ğ‘ ğ‘ ğ‘ğ‘¤ğ‘³ğ‘œğ‘¦ğ‘¯ ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ
        if 'plugin_results' in data:
            sections.append(self._format_plugin_results(data['plugin_results']))
        
        # ğ‘ ğ‘ ğ‘•ğ‘§ğ‘’ğ‘–ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯
        if 'sections' in data:
            sections.append(self._format_section_info(data['sections']))
        
        # ğ‘ ğ‘ ğ‘©ğ‘¯ğ‘¦ ğ‘§ğ‘®ğ‘¼ğ‘Ÿ
        if 'errors' in data and data['errors']:
            sections.append(self._format_errors(data['errors']))
        
        return '\n'.join(sections)
    
    def _format_analysis_results(self, results: Dict[str, Any]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘ ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘¦ğ‘Ÿğ‘¦ğ‘• ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ ğ‘¦ğ‘¯ğ‘‘ HTML"""
        html = "<h2>ğŸ“Š Analysis Results</h2>\n"
        
        # ğ‘ ğ‘¯ ğ‘ ğ‘•ğ‘‘ğ‘©ğ‘‘ğ‘¦ğ‘•ğ‘‘ğ‘¦ğ‘’ğ‘• ğ‘
        if 'statistics' in results:
            stats = results['statistics']
            html += '<div class="stat-grid">\n'
            
            for key, value in stats.items():
                html += f'''
                <div class="stat-card">
                    <h4>{key.replace('_', ' ').title()}</h4>
                    <div class="stat-value">{value}</div>
                </div>
                '''
            
            html += '</div>\n'
        
        return html
    
    def _format_plugin_results(self, results: Dict[str, Any]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘ ğ‘ğ‘¤ğ‘³ğ‘œğ‘¦ğ‘¯ ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ ğ‘¦ğ‘¯ğ‘‘ HTML"""
        html = "<h2>ğŸ”Œ Plugin Analysis Results</h2>\n"
        
        for plugin_name, plugin_result in results.items():
            html += f"<h3>{plugin_name.replace('_', ' ').title()}</h3>\n"
            
            if 'error' in plugin_result:
                html += f'<div class="error"><strong>Error:</strong> {plugin_result["error"]}</div>\n'
            else:
                # ğ‘ ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘“ğ‘¦ğ‘¯ğ‘›ğ‘¦ğ‘™ğ‘Ÿ ğ‘¦ğ‘“ ğ‘ğ‘¦ğ‘• ğ‘¦ğ‘Ÿ ğ‘ ğ‘§ğ‘¯ğ‘‘ğ‘®ğ‘©ğ‘ğ‘¦ ğ‘ğ‘¤ğ‘³ğ‘œğ‘¦ğ‘¯
                if plugin_name == 'entropy_analysis' and 'overall_assessment' in plugin_result:
                    assessment = plugin_result['overall_assessment']
                    if assessment.get('likely_packed'):
                        html += '<div class="warning"><strong>âš ï¸ Potential Packing Detected</strong><br>'
                        html += f"High entropy sections: {', '.join(assessment.get('high_entropy_sections', []))}</div>\n"
                
                # ğ‘ ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘‘ğ‘¼ğ‘§ğ‘•ğ‘‘ğ‘¦ğ‘™ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ğ‘Ÿ ğ‘¦ğ‘“ ğ‘ğ‘¦ğ‘• ğ‘¦ğ‘Ÿ ğ‘ ğ‘•ğ‘‘ğ‘®ğ‘¦ğ‘™ ğ‘ğ‘¤ğ‘³ğ‘œğ‘¦ğ‘¯
                if plugin_name == 'string_extraction' and 'summary' in plugin_result:
                    summary = plugin_result['summary']
                    if summary.get('interesting_strings'):
                        html += "<h4>ğŸ” Interesting Strings Found</h4>\n"
                        html += "<table>\n<tr><th>String</th><th>Section</th><th>Score</th></tr>\n"
                        
                        for string_info in summary['interesting_strings'][:10]:  # ğ‘•ğ‘´ ğ‘´ğ‘¯ğ‘¤ğ‘¦ ğ‘ ğ‘‘ğ‘©ğ‘ 10
                            html += f"""
                            <tr>
                                <td><code>{string_info.get('value', '')[:50]}...</code></td>
                                <td>{string_info.get('section', '')}</td>
                                <td>{string_info.get('score', 0):.1f}</td>
                            </tr>
                            """
                        html += "</table>\n"
        
        return html
    
    def _format_section_info(self, sections: Dict[str, Any]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘ ğ‘•ğ‘§ğ‘’ğ‘–ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘‘ HTML"""
        html = "<h2>ğŸ“‚ Binary Sections</h2>\n"
        
        if sections:
            html += """
            <table>
            <tr>
                <th>Section Name</th>
                <th>Size</th>
                <th>Virtual Address</th>
                <th>Type</th>
                <th>Characteristics</th>
            </tr>
            """
            
            for section_name, section_info in sections.items():
                size = section_info.get('size', 0)
                vaddr = section_info.get('virtual_address', 0)
                characteristics = section_info.get('characteristics', 0)
                section_type = section_info.get('type', 'Unknown')
                
                html += f"""
                <tr>
                    <td><code>{section_name}</code></td>
                    <td>{size} bytes</td>
                    <td>0x{vaddr:x}</td>
                    <td>{section_type}</td>
                    <td>0x{characteristics:x}</td>
                </tr>
                """
            
            html += "</table>\n"
        
        return html
    
    def _format_errors(self, errors: List[str]) -> str:
        """ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘ ğ‘§ğ‘®ğ‘¼ ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘¦ğ‘¯ğ‘‘ HTML"""
        html = "<h2>âŒ Errors</h2>\n"
        
        for error in errors:
            html += f'<div class="error">{error}</div>\n'
        
        return html
    
    def get_file_extension(self) -> str:
        return ".html"


class ReportGenerator:
    """ğ‘ ğ‘¢ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ğ‘¼ - ğ‘’ğ‘©ğ‘¯ğ‘’ğ‘®ğ‘°ğ‘Ÿ ğ‘¯ ğ‘’ğ‘ªğ‘¯ğ‘ğ‘»ğ‘‘ ğ‘›ğ‘±ğ‘‘ğ‘© ğ‘¦ğ‘¯ğ‘‘ ğ‘ğ‘¸ğ‘¦ğ‘©ğ‘• ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ğ‘Ÿ"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self.formatters = {
            'json': JSONReportFormatter(config),
            'yaml': YAMLReportFormatter(config),
            'xml': XMLReportFormatter(config),
            'html': HTMLReportFormatter(config)
        }
    
    def generate_report(self, data: Dict[str, Any], format_type: str = 'json', 
                       output_file: Optional[str] = None) -> str:
        """ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘© ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘¦ğ‘¯ ğ‘ ğ‘•ğ‘ğ‘§ğ‘•ğ‘¦ğ‘“ğ‘²ğ‘› ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘"""
        # ğ‘¨ğ‘› ğ‘¥ğ‘§ğ‘‘ğ‘©ğ‘›ğ‘±ğ‘‘ğ‘© ğ‘¦ğ‘“ ğ‘¯ğ‘ªğ‘‘ ğ‘©ğ‘¤ğ‘®ğ‘§ğ‘›ğ‘¦ ğ‘¦ğ‘¯ğ‘’ğ‘¤ğ‘¿ğ‘›ğ‘¦ğ‘›
        if 'metadata' not in data:
            data['metadata'] = self._generate_metadata()
        
        # ğ‘ğ‘¨ğ‘¤ğ‘¦ğ‘›ğ‘±ğ‘‘ ğ‘ ğ‘“ğ‘¹ğ‘¥ğ‘¨ğ‘‘ ğ‘‘ğ‘²ğ‘
        if format_type not in self.formatters:
            available_formats = list(self.formatters.keys())
            raise ValueError(f"Unsupported format: {format_type}. Available formats: {available_formats}")
        
        # ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘
        formatter = self.formatters[format_type]
        report_content = formatter.format(data)
        
        # ğ‘•ğ‘±ğ‘ ğ‘‘ ğ‘ ğ‘¦ğ‘“ ğ‘ ğ‘¦ ğ‘¯ğ‘µğ‘• ğ‘“ğ‘²ğ‘¤ ğ‘® ğ‘•ğ‘ğ‘§ğ‘•ğ‘¦ğ‘“ğ‘²ğ‘›
        if output_file:
            # ğ‘¦ğ‘¯ğ‘–ğ‘«ğ‘¼ ğ‘ ğ‘“ğ‘²ğ‘¤ ğ‘£ğ‘¨ğ‘Ÿ ğ‘ ğ‘®ğ‘²ğ‘‘ ğ‘§ğ‘’ğ‘•ğ‘‘ğ‘§ğ‘¯ğ‘–ğ‘©ğ‘¯
            if not output_file.endswith(formatter.get_file_extension()):
                output_file += formatter.get_file_extension()
            
            # ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘ ğ‘›ğ‘²ğ‘®ğ‘§ğ‘’ğ‘‘ğ‘¼ğ‘¦ ğ‘¦ğ‘“ ğ‘¦ğ‘‘ ğ‘›ğ‘³ğ‘Ÿğ‘©ğ‘¯ğ‘‘ ğ‘§ğ‘’ğ‘Ÿğ‘¦ğ‘•ğ‘‘
            output_dir = os.path.dirname(output_file)
            if output_dir:  # ğ‘´ğ‘¯ğ‘¤ğ‘¦ ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘›ğ‘²ğ‘®ğ‘§ğ‘’ğ‘‘ğ‘¼ğ‘¦ ğ‘¦ğ‘“ ğ‘¯ğ‘ªğ‘‘ ğ‘§ğ‘¥ğ‘ğ‘‘ğ‘¦
                os.makedirs(output_dir, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"[+] Report saved to: {output_file}")
        
        return report_content
    
    def _generate_metadata(self) -> Dict[str, Any]:
        """ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘¥ğ‘§ğ‘‘ğ‘©ğ‘›ğ‘±ğ‘‘ğ‘© ğ‘“ğ‘¹ ğ‘ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘"""
        return {
            'timestamp': datetime.now().isoformat(),
            'framework_version': self.config.framework.version,
            'generator': 'Cumpyl Framework',
            'config_file': getattr(self.config, 'config_path', 'default')
        }
    
    def create_analysis_report(self, target_file: str, analysis_results: Dict[str, Any], 
                             plugin_results: Dict[str, Any] = None, 
                             errors: List[str] = None) -> Dict[str, Any]:
        """ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘© ğ‘ ğ‘ ğ‘ ğ‘’ğ‘©ğ‘¥ğ‘ğ‘¤ğ‘°ğ‘‘ ğ‘©ğ‘¯ğ‘¨ğ‘¤ğ‘¦ğ‘Ÿğ‘¦ğ‘• ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘"""
        report_data = {
            'metadata': self._generate_metadata(),
            'target_file': target_file,
            'analysis_results': analysis_results,
            'errors': errors or []
        }
        
        # ğ‘¨ğ‘› ğ‘ ğ‘– ğ‘ target ğ‘“ğ‘²ğ‘¤ ğ‘¦ğ‘¯ğ‘“ ğ‘¦ğ‘¯ ğ‘ metadata
        if os.path.exists(target_file):
            report_data['metadata'].update({
                'target_file': os.path.abspath(target_file),
                'target_file_size': os.path.getsize(target_file),
                'target_file_modified': datetime.fromtimestamp(os.path.getmtime(target_file)).isoformat()
            })
        
        # ğ‘¨ğ‘› ğ‘ ğ‘ğ‘¤ğ‘³ğ‘œğ‘¦ğ‘¯ ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ ğ‘¦ğ‘“ ğ‘ ğ‘¦ ğ‘
        if plugin_results:
            report_data['plugin_results'] = plugin_results
        
        return report_data
    
    def get_available_formats(self) -> List[str]:
        """ğ‘œğ‘§ğ‘‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ list ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘"""
        return list(self.formatters.keys())
    
    def create_batch_report(self, batch_results: Dict[str, Any]) -> Dict[str, Any]:
        """ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘© ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘“ğ‘¹ ğ‘šğ‘¨ğ‘— ğ‘ğ‘®ğ‘©ğ‘•ğ‘§ğ‘•ğ‘¦ğ‘™ ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ğ‘Ÿ"""
        report_data = {
            'metadata': self._generate_metadata(),
            'report_type': 'batch_processing',
            'batch_summary': {
                'total_files': batch_results.get('total', 0),
                'completed_files': batch_results.get('completed', 0),
                'failed_files': batch_results.get('failed', 0),
                'success_rate': f"{(batch_results.get('completed', 0) / batch_results.get('total', 1) * 100):.1f}%",
                'total_duration': f"{batch_results.get('duration', 0):.2f} seconds"
            },
            'completed_jobs': [],
            'failed_jobs': [],
            'errors': []
        }
        
        # ğ‘¨ğ‘› ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘©ğ‘šğ‘¬ğ‘‘ ğ‘’ğ‘©ğ‘¥ğ‘ğ‘¤ğ‘°ğ‘‘ğ‘¦ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ
        for job in batch_results.get('completed_jobs', []):
            job_info = {
                'file': job.input_file,
                'output': job.output_file,
                'duration': f"{job.get_duration():.2f}s",
                'operations': len(job.operations),
                'results': job.results
            }
            report_data['completed_jobs'].append(job_info)
        
        # ğ‘¨ğ‘› ğ‘¦ğ‘¯ğ‘“ğ‘¼ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘©ğ‘šğ‘¬ğ‘‘ ğ‘“ğ‘±ğ‘¤ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ
        for job in batch_results.get('failed_jobs', []):
            job_info = {
                'file': job.input_file,
                'error': job.error,
                'duration': f"{job.get_duration():.2f}s",
                'operations': len(job.operations)
            }
            report_data['failed_jobs'].append(job_info)
            report_data['errors'].append(f"{job.input_file}: {job.error}")
        
        return report_data
    
    def generate_batch_report_chunked(self, batch_results: Dict[str, Any], format_type: str = 'json', 
                                    output_file_base: Optional[str] = None) -> List[str]:
        """ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘šğ‘¨ğ‘— ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘¦ğ‘¯ ğ‘¥ğ‘©ğ‘¤ğ‘‘ğ‘¦ğ‘ğ‘©ğ‘¤ ğ‘—ğ‘³ğ‘™ğ‘’ğ‘• ğ‘¦ğ‘“ ğ‘‘ğ‘µ ğ‘¤ğ‘¸ğ‘¡"""
        
        if not self.config.output.split_large_reports:
            # ğ‘¦ğ‘“ ğ‘•ğ‘ğ‘¤ğ‘¦ğ‘‘ğ‘¦ğ‘™ ğ‘¦ğ‘Ÿ ğ‘›ğ‘¦ğ‘Ÿğ‘±ğ‘šğ‘©ğ‘¤ğ‘›, ğ‘¿ğ‘Ÿ ğ‘®ğ‘§ğ‘œğ‘¿ğ‘¤ğ‘¼ ğ‘šğ‘¨ğ‘— ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘¥ğ‘§ğ‘”ğ‘©ğ‘›
            report_data = self.generate_batch_report_data(batch_results)
            output_file = output_file_base or f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.generate_report(report_data, format_type, output_file)
            return [output_file]
        
        # ğ‘œğ‘§ğ‘‘ ğ‘’ğ‘©ğ‘¥ğ‘ğ‘¤ğ‘°ğ‘‘ğ‘¦ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ ğ‘¯ ğ‘—ğ‘³ğ‘™ğ‘’ ğ‘ğ‘§ğ‘¥
        completed_jobs = batch_results.get('completed_jobs', [])
        failed_jobs = batch_results.get('failed_jobs', [])
        
        chunk_size = self.config.output.files_per_chunk
        output_files = []
        
        # ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘—ğ‘³ğ‘™ğ‘’ğ‘• ğ‘ ğ‘’ğ‘©ğ‘¥ğ‘ğ‘¤ğ‘°ğ‘‘ğ‘¦ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ
        for i in range(0, len(completed_jobs), chunk_size):
            chunk_jobs = completed_jobs[i:i + chunk_size]
            chunk_num = (i // chunk_size) + 1
            total_chunks = (len(completed_jobs) + chunk_size - 1) // chunk_size
            
            # ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘© ğ‘—ğ‘³ğ‘™ğ‘’-ğ‘•ğ‘ğ‘§ğ‘•ğ‘¦ğ‘“ğ‘¦ğ‘’ ğ‘šğ‘¨ğ‘— ğ‘®ğ‘¦ğ‘Ÿğ‘³ğ‘¤ğ‘‘ ğ‘›ğ‘¦ğ‘’ğ‘–ğ‘©ğ‘¯ğ‘§ğ‘®ğ‘¦
            chunk_batch_results = {
                'completed': len(chunk_jobs),
                'failed': 0,  # ğ‘“ğ‘±ğ‘¤ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ ğ‘œğ‘´ ğ‘¦ğ‘¯ ğ‘ ğ‘¤ğ‘­ğ‘•ğ‘‘ ğ‘—ğ‘³ğ‘™ğ‘’
                'total': len(chunk_jobs),
                'duration': sum(job.get_duration() for job in chunk_jobs),
                'completed_jobs': chunk_jobs,
                'failed_jobs': []
            }
            
            # ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘ ğ‘›ğ‘±ğ‘‘ğ‘© ğ‘“ğ‘¹ ğ‘ğ‘¦ğ‘• ğ‘—ğ‘³ğ‘™ğ‘’
            chunk_report_data = self.generate_batch_report_data(chunk_batch_results)
            
            # ğ‘©ğ‘› ğ‘—ğ‘³ğ‘™ğ‘’ ğ‘¦ğ‘¯ğ‘“ğ‘¹ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘‘ ğ‘¥ğ‘§ğ‘‘ğ‘©ğ‘›ğ‘±ğ‘‘ğ‘©
            chunk_report_data['metadata'].update({
                'chunk_number': chunk_num,
                'total_chunks': total_chunks,
                'chunk_size': len(chunk_jobs),
                'chunk_description': f"Chunk {chunk_num} of {total_chunks} (files {i+1}-{min(i+chunk_size, len(completed_jobs))})"
            })
            
            # ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘ ğ‘¬ğ‘‘ğ‘ğ‘«ğ‘‘ ğ‘“ğ‘²ğ‘¤ ğ‘¯ğ‘±ğ‘¥
            base_name = output_file_base or f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            chunk_output_file = f"{base_name}_chunk_{chunk_num:03d}_of_{total_chunks:03d}"
            
            # ğ‘¡ğ‘§ğ‘¯ğ‘¼ğ‘±ğ‘‘ ğ‘ ğ‘®ğ‘¦ğ‘ğ‘¹ğ‘‘
            self.generate_report(chunk_report_data, format_type, chunk_output_file)
            output_files.append(chunk_output_file)
            
            print(f"[+] Generated chunk {chunk_num}/{total_chunks}: {chunk_output_file}")
        
        # ğ‘ ğ‘“ğ‘±ğ‘¤ğ‘› ğ‘¡ğ‘ªğ‘šğ‘Ÿ ğ‘¦ğ‘¯ ğ‘© ğ‘•ğ‘§ğ‘ğ‘¼ğ‘¦ğ‘‘ ğ‘ğ‘¦ğ‘¤ (ğ‘¦ğ‘“ ğ‘§ğ‘¯ğ‘¦)
        if failed_jobs:
            failed_batch_results = {
                'completed': 0,
                'failed': len(failed_jobs),
                'total': len(failed_jobs),
                'duration': sum(job.get_duration() for job in failed_jobs),
                'completed_jobs': [],
                'failed_jobs': failed_jobs
            }
            
            failed_report_data = self.generate_batch_report_data(failed_batch_results)
            failed_report_data['metadata'].update({
                'report_type': 'failed_jobs_summary',
                'description': f"Summary of {len(failed_jobs)} failed jobs"
            })
            
            base_name = output_file_base or f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            failed_output_file = f"{base_name}_failed_jobs"
            
            self.generate_report(failed_report_data, format_type, failed_output_file)
            output_files.append(failed_output_file)
            
            print(f"[+] Generated failed jobs report: {failed_output_file}")
        
        # ğ‘’ğ‘®ğ‘¦ğ‘±ğ‘‘ ğ‘© ğ‘•ğ‘³ğ‘¥ğ‘¼ğ‘¦ ğ‘ğ‘¦ğ‘¤ ğ‘¢ğ‘¦ğ‘ ğ‘¦ğ‘¯ğ‘“ğ‘¹ğ‘¥ğ‘±ğ‘–ğ‘©ğ‘¯ ğ‘©ğ‘šğ‘¬ğ‘‘ ğ‘·ğ‘¤ ğ‘—ğ‘³ğ‘™ğ‘’ğ‘•
        summary_data = {
            'metadata': self._generate_metadata(),
            'batch_summary': {
                'total_files': len(completed_jobs) + len(failed_jobs),
                'completed_files': len(completed_jobs),
                'failed_files': len(failed_jobs),
                'success_rate': f"{(len(completed_jobs) / (len(completed_jobs) + len(failed_jobs)) * 100):.1f}%" if (completed_jobs or failed_jobs) else "0%",
                'total_chunks_generated': len(output_files),
                'chunk_files': output_files,
                'chunk_size': chunk_size
            }
        }
        
        summary_data['metadata'].update({
            'report_type': 'batch_processing_summary',
            'description': f"Summary of batch processing split into {len(output_files)} chunks"
        })
        
        base_name = output_file_base or f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        summary_output_file = f"{base_name}_summary"
        
        self.generate_report(summary_data, format_type, summary_output_file)
        output_files.insert(0, summary_output_file)  # ğ‘¨ğ‘› ğ‘•ğ‘³ğ‘¥ğ‘¼ğ‘¦ ğ‘¨ğ‘‘ ğ‘ ğ‘šğ‘¦ğ‘œğ‘¦ğ‘¯ğ‘¦ğ‘™
        
        print(f"[+] Generated summary report: {summary_output_file}")
        print(f"[+] Total files generated: {len(output_files)}")
        
        return output_files